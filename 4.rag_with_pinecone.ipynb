{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e8aada",
   "metadata": {},
   "source": [
    "1. 문서의 내용을 읽는다.\n",
    "2. 문서를 쪼갠다\n",
    "    - 토큰 수 초과로 답변을 생성하지 못할 수 있음\n",
    "    - 문서가 길면(인풋이 길면) 답변 생성이 오래걸림\n",
    "3. 임베딩 => 벡터 데이터베이스에 저장\n",
    "4. 질문이 있을 때, 백터 데이터베이스에 유사도 검색\n",
    "5. 유사도 검색으로 가져온 문서를 LLM에 질문과 같이 전달"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44845898",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet docx2txt langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader(\"./tax.docx\")\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520226fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500, # 하나의 청크가 가질 수 있는 크기\n",
    "    chunk_overlap=200, # 청크를 쪼갤때 겹치는 범위 => 유사도 검색을 진행할 때 성공 확률을 높이기 위해\n",
    ")\n",
    "loader = Docx2txtLoader(\"./tax.docx\")\n",
    "document_list = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd30f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba86660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name= 'tax-index'\n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "pc=Pinecone(api_key = pinecone_api_key)\n",
    "\n",
    "database = PineconeVectorStore.from_documents(document_list, embedding, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c162719",
   "metadata": {},
   "outputs": [],
   "source": [
    "query='연봉 5천만원인 직장인의 소득세는 얼마인가요?'\n",
    "retrived_docs = database.similarity_search(query) # 유사도 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad3f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"[Identity]\n",
    "- 당신은 최고의 한국 소득세 전문가 입니다.\n",
    "- [Context]를 참고해서 사용자의 질문에 답변해주세요\n",
    "\n",
    "[Context]\n",
    "{retrived_docs}\n",
    "\n",
    "Question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d54842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16216cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, retriever=database.as_retriever(), chain_type_kwargs={\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = qa_chain({\n",
    "    \"query\": query\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
