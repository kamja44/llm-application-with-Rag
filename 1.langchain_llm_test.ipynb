{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee05467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.76 (from langchain-openai)\n",
      "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting openai<2.0.0,>=1.104.2 (from langchain-openai)\n",
      "  Downloading openai-1.107.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Downloading langsmith-0.4.27-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\yes\\anaconda3\\envs\\inflearn-llm-application\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\yes\\anaconda3\\envs\\inflearn-llm-application\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.76->langchain-openai) (25.0)\n",
      "Collecting pydantic>=2.7.4 (from langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\yes\\anaconda3\\envs\\inflearn-llm-application\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai) (1.3.0)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain-openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading regex-2025.9.1-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain-openai)\n",
      "  Downloading zstandard-0.24.0-cp310-cp310-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
      "  Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\yes\\anaconda3\\envs\\inflearn-llm-application\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.104.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
      "Downloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading openai-1.107.1-py3-none-any.whl (945 kB)\n",
      "   ---------------------------------------- 0.0/945.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 945.2/945.2 kB 11.0 MB/s  0:00:00\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 10.8 MB/s  0:00:00\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.2/884.2 kB 9.9 MB/s  0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.27-py3-none-any.whl (384 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-win_amd64.whl (131 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Downloading regex-2025.9.1-cp310-cp310-win_amd64.whl (276 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp310-cp310-win_amd64.whl (107 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.24.0-cp310-cp310-win_amd64.whl (505 kB)\n",
      "Installing collected packages: zstandard, urllib3, typing-inspection, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pydantic-core, orjson, jsonpointer, jiter, idna, h11, distro, charset_normalizer, certifi, annotated-types, requests, pydantic, jsonpatch, httpcore, anyio, tiktoken, requests-toolbelt, httpx, openai, langsmith, langchain-core, langchain-openai\n",
      "\n",
      "   - --------------------------------------  1/31 [urllib3]\n",
      "   ----- ----------------------------------  4/31 [tenacity]\n",
      "   --------- ------------------------------  7/31 [PyYAML]\n",
      "   --------------- ------------------------ 12/31 [jiter]\n",
      "   ------------------- -------------------- 15/31 [distro]\n",
      "   ------------------------ --------------- 19/31 [requests]\n",
      "   ------------------------- -------------- 20/31 [pydantic]\n",
      "   ------------------------- -------------- 20/31 [pydantic]\n",
      "   ---------------------------- ----------- 22/31 [httpcore]\n",
      "   ----------------------------- ---------- 23/31 [anyio]\n",
      "   -------------------------------- ------- 25/31 [requests-toolbelt]\n",
      "   --------------------------------- ------ 26/31 [httpx]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ---------------------------------- ----- 27/31 [openai]\n",
      "   ------------------------------------ --- 28/31 [langsmith]\n",
      "   ------------------------------------ --- 28/31 [langsmith]\n",
      "   ------------------------------------- -- 29/31 [langchain-core]\n",
      "   ------------------------------------- -- 29/31 [langchain-core]\n",
      "   ------------------------------------- -- 29/31 [langchain-core]\n",
      "   ------------------------------------- -- 29/31 [langchain-core]\n",
      "   ------------------------------------- -- 29/31 [langchain-core]\n",
      "   -------------------------------------- - 30/31 [langchain-openai]\n",
      "   ---------------------------------------- 31/31 [langchain-openai]\n",
      "\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.10.0 certifi-2025.8.3 charset_normalizer-3.4.3 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.76 langchain-openai-0.3.33 langsmith-0.4.27 openai-1.107.1 orjson-3.11.3 pydantic-2.11.7 pydantic-core-2.33.2 python-dotenv-1.1.1 regex-2025.9.1 requests-2.32.5 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.11.0 tqdm-4.67.1 typing-inspection-0.4.1 urllib3-2.5.0 zstandard-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a72117b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a916b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b3cba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인프런에는 다양한 분야의 강의가 있습니다. 프로그래밍, 디자인, 비즈니스, 언어 등 다양한 주제로 강의가 제공되고 있습니다. 실무 경험이 풍부한 강사들이 직접 강의를 진행하므로 실무에 필요한 지식을 쉽게 습득할 수 있습니다. 또한, 강의 내용은 초급부터 고급까지 다양한 수준으로 제공되어 있어 자신의 수준에 맞게 공부할 수 있습니다. 원하는 분야나 주제에 맞는 강의를 찾아보시면 도움이 될 것입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 26, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CEy7F7XsOPI8SWHMmaVWKNTVJtoeM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--41dac2bf-311e-47d3-8727-450019a87419-0', usage_metadata={'input_tokens': 26, 'output_tokens': 207, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"인프런에 어떤 강의가 있나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ebaee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인프런은 다양한 분야의 강의가 제공되는 온라인 교육 플랫폼입니다. 주요 강의 카테고리로는 프로그래밍, 디자인, 비즈니스, 데이터 분석, 마케팅, 투자 및 재무, 자기계발 등이 있습니다. 관심 있는 분야나 배우고 싶은 스킬에 맞는 강의를 찾아 수강할 수 있습니다. 또한 유명한 전문가나 업계 강사가 진행하는 강의도 많이 제공되어 있어 실무에서 바로 활용할 수 있는 실용적인 내용을 학습할 수 있습니다. 인프런의 강의는 온라인 동영상으로 제공되며, 수강 후에는 강의를 수료한 증명서도 발급 받을 수 있습니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm.invoke(\"인프런에 어떤 강의가 있나요?\")\n",
    "ai_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529cefe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
